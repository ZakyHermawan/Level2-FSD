{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Highway-Object-Detection-40 to yolov9:: 100%|██████████| 169620/169620 [00:33<00:00, 5094.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Highway-Object-Detection-40 in yolov9:: 100%|██████████| 4896/4896 [00:00<00:00, 8439.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"bcUxEe1xSbzdHOvocd0d\")\n",
    "project = rf.workspace(\"universitas-tidar\").project(\"highway-object-detection\")\n",
    "version = project.version(40)\n",
    "dataset = version.download(\"yolov9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=weights/yolov9-m.pt, cfg=models/detect/yolov9-m.yaml, data=Highway-Object-Detection-40/data.yaml, hyp=hyp.scratch-high.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov9-m-finetuning, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.9.19 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7933MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1         0  models.common.Silence                   []                            \n",
      "  1                -1  1       928  models.common.Conv                      [3, 32, 3, 2]                 \n",
      "  2                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  3                -1  1    171648  models.common.RepNCSPELAN4              [64, 128, 128, 64, 1]         \n",
      "  4                -1  1    276960  models.common.AConv                     [128, 240]                    \n",
      "  5                -1  1    629520  models.common.RepNCSPELAN4              [240, 240, 240, 120, 1]       \n",
      "  6                -1  1    778320  models.common.AConv                     [240, 360]                    \n",
      "  7                -1  1   1414080  models.common.RepNCSPELAN4              [360, 360, 360, 180, 1]       \n",
      "  8                -1  1   1556160  models.common.AConv                     [360, 480]                    \n",
      "  9                -1  1   2511840  models.common.RepNCSPELAN4              [480, 480, 480, 240, 1]       \n",
      " 10                -1  1    577440  models.common.SPPELAN                   [480, 480, 240]               \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   1586880  models.common.RepNCSPELAN4              [840, 360, 360, 180, 1]       \n",
      " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
      " 16                -1  1    715920  models.common.RepNCSPELAN4              [600, 240, 240, 120, 1]       \n",
      " 17                -1  1    397808  models.common.AConv                     [240, 184]                    \n",
      " 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   1480320  models.common.RepNCSPELAN4              [544, 360, 360, 180, 1]       \n",
      " 20                -1  1    778080  models.common.AConv                     [360, 240]                    \n",
      " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 22                -1  1   2627040  models.common.RepNCSPELAN4              [720, 480, 480, 240, 1]       \n",
      " 23                 5  1     57840  models.common.CBLinear                  [240, [240]]                  \n",
      " 24                 7  1    216600  models.common.CBLinear                  [360, [240, 360]]             \n",
      " 25                 9  1    519480  models.common.CBLinear                  [480, [240, 360, 480]]        \n",
      " 26                 0  1       928  models.common.Conv                      [3, 32, 3, 2]                 \n",
      " 27                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      " 28                -1  1    171648  models.common.RepNCSPELAN4              [64, 128, 128, 64, 1]         \n",
      " 29                -1  1    276960  models.common.AConv                     [128, 240]                    \n",
      " 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n",
      " 31                -1  1    629520  models.common.RepNCSPELAN4              [240, 240, 240, 120, 1]       \n",
      " 32                -1  1    778320  models.common.AConv                     [240, 360]                    \n",
      " 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n",
      " 34                -1  1   1414080  models.common.RepNCSPELAN4              [360, 360, 360, 180, 1]       \n",
      " 35                -1  1   1556160  models.common.AConv                     [360, 480]                    \n",
      " 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n",
      " 37                -1  1   2511840  models.common.RepNCSPELAN4              [480, 480, 480, 240, 1]       \n",
      " 38[31, 34, 37, 16, 19, 22]  1   9096542  models.yolo.DualDDetect                 [5, [240, 360, 480, 240, 360, 480]]\n",
      "yolov9-m summary: 938 layers, 32769982 parameters, 32769950 gradients, 132.4 GFLOPs\n",
      "\n",
      "Transferred 1400/1412 items from weights/yolov9-m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 230 weight(decay=0.0), 247 weight(decay=0.0005), 245 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/irman/Documents/yolov9/Highway-Object-Detection-40/train/l\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/irman/Documents/yolov9/Highway-Object-Detection-40/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/irman/Documents/yolov9/Highway-Object-Detection-40/valid/lab\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/irman/Documents/yolov9/Highway-Object-Detection-40/valid/labels.cache\n",
      "Plotting labels to runs/train/yolov9-m-finetuning/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov9-m-finetuning\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       0/29      6.95G      1.332      4.988      1.849         29        640:  Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
      "       0/29      7.31G      1.227      4.778      1.591         55        640:  Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/29      7.31G      1.179        4.8       1.56         34        640:  Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "       0/29      7.37G      1.024       1.83      1.423         68        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.749      0.749      0.791      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/29      7.38G      1.032      1.159      1.404         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.874      0.751      0.846      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/29      7.38G      1.134      1.273      1.489         35        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.734       0.66       0.71      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/29      7.38G      1.287      1.458      1.597         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.689      0.677      0.691      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/29      7.38G       1.33      1.493      1.623         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.634      0.486      0.541      0.373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/29      7.38G      1.331      1.488      1.626         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.801      0.621      0.719       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/29      7.38G      1.266      1.356        1.6         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.658      0.699      0.705      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/29      7.38G      1.319      1.394      1.639         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.729      0.659      0.733       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/29      7.38G      1.256      1.317      1.598         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858       0.79       0.68      0.772      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/29      7.38G      1.246      1.244      1.569         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.812      0.663      0.748      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/29      7.38G      1.228      1.244      1.565         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.799      0.715      0.793      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/29      7.38G      1.222       1.22      1.561         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.852      0.674      0.811      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/29      7.38G      1.193      1.155      1.537         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.858      0.716      0.805      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/29      7.38G      1.178      1.132      1.536         57        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.834      0.709      0.811      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/29      7.38G      1.149      1.098       1.52         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.867      0.705      0.818      0.616\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/29      7.39G     0.9889      0.923      1.466         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.841      0.713      0.814      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/29      7.39G      1.003     0.9088      1.463         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.864      0.709      0.807      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/29      7.39G     0.9736     0.8574      1.459         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.798      0.719      0.799      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/29      7.39G     0.9524     0.8157      1.444         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858       0.81      0.737      0.819      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/29      7.39G     0.9384     0.7933      1.435         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.879      0.713      0.811      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/29      7.39G     0.9134     0.7241      1.413         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858       0.89      0.739       0.84      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/29      7.39G     0.8858     0.7149      1.383         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.838      0.753      0.833      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/29      7.39G     0.8876     0.6706      1.373         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.879       0.77      0.851      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/29      7.39G     0.8358     0.6387       1.35         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.877      0.786      0.859      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/29      7.39G     0.8339     0.6183      1.343         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858       0.89      0.761       0.86      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/29      7.39G     0.7944     0.5768      1.316         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.898      0.776      0.846       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/29      7.39G     0.7912     0.5689      1.311         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.882      0.793      0.866      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/29      7.39G     0.7654     0.5476      1.303         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858       0.92      0.787      0.885      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/29      7.39G     0.7451     0.5179      1.279         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.942      0.789      0.886      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/29      7.39G     0.7312     0.4872      1.259         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.922      0.806       0.88      0.696\n",
      "\n",
      "30 epochs completed in 0.983 hours.\n",
      "Optimizer stripped from runs/train/yolov9-m-finetuning/weights/last.pt, 66.3MB\n",
      "Optimizer stripped from runs/train/yolov9-m-finetuning/weights/best.pt, 66.3MB\n",
      "\n",
      "Validating runs/train/yolov9-m-finetuning/weights/best.pt...\n",
      "Fusing layers... \n",
      "yolov9-m summary: 588 layers, 32558950 parameters, 0 gradients, 130.7 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-44:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-43:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-46:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-45:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-47:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858      0.942      0.789      0.886      0.697\n",
      "                   bus        487        126      0.935      0.798      0.879      0.776\n",
      "                   car        487        332      0.921      0.898      0.948      0.831\n",
      "             motorbike        487         44       0.97       0.74      0.858      0.548\n",
      "                person        487         65      0.937      0.677      0.823      0.539\n",
      "                 truck        487        291      0.947      0.832      0.922      0.792\n",
      "Results saved to \u001b[1mruns/train/yolov9-m-finetuning\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train yolov9 models\n",
    "!python train_dual.py --workers 8 --device 0 --batch 8 --data 'Highway-Object-Detection-40/data.yaml' --img 640 --cfg models/detect/yolov9-m.yaml --weights 'weights/yolov9-m.pt' --name yolov9-m-finetuning --hyp hyp.scratch-high.yaml --min-items 0 --epochs 30 --close-mosaic 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval_dual: \u001b[0mdata=Highway-Object-Detection-40/data.yaml, weights=['runs/train/yolov9-m-finetuning/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=yolov9_m_640_val, exist_ok=False, half=False, dnn=False, min_items=0\n",
      "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.9.19 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7933MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-m summary: 588 layers, 32558950 parameters, 0 gradients, 130.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/irman/Documents/yolov9/Highway-Object-Detection-40/valid/lab\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"/home/irman/Documents/yolov9/utils/plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        487        858       0.94       0.79      0.885      0.698\n",
      "                   bus        487        126      0.935      0.799      0.881      0.777\n",
      "                   car        487        332      0.917      0.898      0.948      0.831\n",
      "             motorbike        487         44       0.97      0.747      0.851      0.545\n",
      "                person        487         65      0.933      0.677      0.825      0.548\n",
      "                 truck        487        291      0.946      0.832      0.922      0.792\n",
      "Speed: 0.2ms pre-process, 32.2ms inference, 0.8ms NMS per image at shape (16, 3, 640, 640)\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/val/yolov9_m_640_val/best_predictions.json...\n",
      "loading annotations into memory...\n",
      "pycocotools unable to run: [Errno 2] No such file or directory: '/home/irman/Documents/yolov9/annotations/instances_val2017.json'\n",
      "Results saved to \u001b[1mruns/val/yolov9_m_640_val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val_dual.py --data 'Highway-Object-Detection-40/data.yaml' --img 640 --batch 16 --conf 0.001 --iou 0.7 --device 0 --weights 'runs/train/yolov9-m-finetuning/weights/best.pt' --save-json --name yolov9_m_640_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['runs/train/yolov9-m-finetuning/weights/best.pt'], source=videos/jalan_tol.mp4, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=yolov9_m_640, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.9.19 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7933MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-m summary: 588 layers, 32558950 parameters, 0 gradients, 130.7 GFLOPs\n",
      "video 1/1 (1/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 117.2ms\n",
      "video 1/1 (2/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.7ms\n",
      "video 1/1 (3/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.6ms\n",
      "video 1/1 (4/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (5/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.8ms\n",
      "video 1/1 (6/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.3ms\n",
      "video 1/1 (7/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (8/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.0ms\n",
      "video 1/1 (9/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 19.3ms\n",
      "video 1/1 (10/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.4ms\n",
      "video 1/1 (11/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.8ms\n",
      "video 1/1 (12/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.7ms\n",
      "video 1/1 (13/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (14/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.1ms\n",
      "video 1/1 (15/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 14.8ms\n",
      "video 1/1 (16/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (17/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 15.7ms\n",
      "video 1/1 (18/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.0ms\n",
      "video 1/1 (19/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (20/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (21/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (22/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (23/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.2ms\n",
      "video 1/1 (24/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.7ms\n",
      "video 1/1 (25/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (26/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (27/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (28/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.4ms\n",
      "video 1/1 (29/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.4ms\n",
      "video 1/1 (30/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 16.5ms\n",
      "video 1/1 (31/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (32/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (33/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 17.4ms\n",
      "video 1/1 (34/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 15.6ms\n",
      "video 1/1 (35/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 15.8ms\n",
      "video 1/1 (36/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.0ms\n",
      "video 1/1 (37/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (38/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (39/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 17.0ms\n",
      "video 1/1 (40/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 15.7ms\n",
      "video 1/1 (41/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 person, 1 truck, 17.3ms\n",
      "video 1/1 (42/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 15.5ms\n",
      "video 1/1 (43/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 19.0ms\n",
      "video 1/1 (44/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 person, 1 truck, 15.6ms\n",
      "video 1/1 (45/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 person, 1 truck, 17.7ms\n",
      "video 1/1 (46/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 person, 1 truck, 14.8ms\n",
      "video 1/1 (47/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (48/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (49/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.7ms\n",
      "video 1/1 (50/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (51/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 16.7ms\n",
      "video 1/1 (52/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (53/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.0ms\n",
      "video 1/1 (54/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.1ms\n",
      "video 1/1 (55/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (56/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (57/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (58/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (59/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.2ms\n",
      "video 1/1 (60/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.2ms\n",
      "video 1/1 (61/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 person, 1 truck, 16.3ms\n",
      "video 1/1 (62/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.8ms\n",
      "video 1/1 (63/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.3ms\n",
      "video 1/1 (64/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.2ms\n",
      "video 1/1 (65/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.3ms\n",
      "video 1/1 (66/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.2ms\n",
      "video 1/1 (67/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.4ms\n",
      "video 1/1 (68/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 17.0ms\n",
      "video 1/1 (69/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 15.0ms\n",
      "video 1/1 (70/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 person, 1 truck, 17.0ms\n",
      "video 1/1 (71/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 person, 1 truck, 16.2ms\n",
      "video 1/1 (72/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.8ms\n",
      "video 1/1 (73/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.2ms\n",
      "video 1/1 (74/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 17.6ms\n",
      "video 1/1 (75/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 1 truck, 16.7ms\n",
      "video 1/1 (76/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (77/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (78/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.0ms\n",
      "video 1/1 (79/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (80/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (81/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.6ms\n",
      "video 1/1 (82/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.0ms\n",
      "video 1/1 (83/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (84/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.7ms\n",
      "video 1/1 (85/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 14.9ms\n",
      "video 1/1 (86/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (87/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 14.8ms\n",
      "video 1/1 (88/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (89/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (90/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (91/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.2ms\n",
      "video 1/1 (92/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (93/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.0ms\n",
      "video 1/1 (94/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.6ms\n",
      "video 1/1 (95/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (96/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (97/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.4ms\n",
      "video 1/1 (98/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (99/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.5ms\n",
      "video 1/1 (100/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (101/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.5ms\n",
      "video 1/1 (102/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (103/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.4ms\n",
      "video 1/1 (104/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (105/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.7ms\n",
      "video 1/1 (106/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (107/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (108/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.4ms\n",
      "video 1/1 (109/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (110/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (111/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.5ms\n",
      "video 1/1 (112/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (113/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (114/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.7ms\n",
      "video 1/1 (115/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.1ms\n",
      "video 1/1 (116/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (117/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.4ms\n",
      "video 1/1 (118/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (119/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.6ms\n",
      "video 1/1 (120/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.2ms\n",
      "video 1/1 (121/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 21.1ms\n",
      "video 1/1 (122/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.7ms\n",
      "video 1/1 (123/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (124/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.0ms\n",
      "video 1/1 (125/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.9ms\n",
      "video 1/1 (126/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 19.0ms\n",
      "video 1/1 (127/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.1ms\n",
      "video 1/1 (128/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (129/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.7ms\n",
      "video 1/1 (130/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (131/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.4ms\n",
      "video 1/1 (132/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 22.9ms\n",
      "video 1/1 (133/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 31.3ms\n",
      "video 1/1 (134/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 21.4ms\n",
      "video 1/1 (135/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 26.7ms\n",
      "video 1/1 (136/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (137/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (138/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (139/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.0ms\n",
      "video 1/1 (140/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (141/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (142/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.2ms\n",
      "video 1/1 (143/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.3ms\n",
      "video 1/1 (144/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.1ms\n",
      "video 1/1 (145/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 17.7ms\n",
      "video 1/1 (146/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (147/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.4ms\n",
      "video 1/1 (148/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.1ms\n",
      "video 1/1 (149/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (150/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.5ms\n",
      "video 1/1 (151/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (152/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 25.4ms\n",
      "video 1/1 (153/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.3ms\n",
      "video 1/1 (154/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (155/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.3ms\n",
      "video 1/1 (156/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (157/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.2ms\n",
      "video 1/1 (158/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (159/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.9ms\n",
      "video 1/1 (160/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 17.8ms\n",
      "video 1/1 (161/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.9ms\n",
      "video 1/1 (162/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 17.9ms\n",
      "video 1/1 (163/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (164/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 17.0ms\n",
      "video 1/1 (165/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.4ms\n",
      "video 1/1 (166/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (167/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.0ms\n",
      "video 1/1 (168/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.9ms\n",
      "video 1/1 (169/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (170/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 21.3ms\n",
      "video 1/1 (171/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 19.1ms\n",
      "video 1/1 (172/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.8ms\n",
      "video 1/1 (173/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 18.1ms\n",
      "video 1/1 (174/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (175/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.2ms\n",
      "video 1/1 (176/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (177/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.9ms\n",
      "video 1/1 (178/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.8ms\n",
      "video 1/1 (179/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.4ms\n",
      "video 1/1 (180/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (181/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.6ms\n",
      "video 1/1 (182/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (183/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (184/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (185/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.2ms\n",
      "video 1/1 (186/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (187/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 26.7ms\n",
      "video 1/1 (188/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 20.8ms\n",
      "video 1/1 (189/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.9ms\n",
      "video 1/1 (190/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (191/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 20.9ms\n",
      "video 1/1 (192/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (193/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 20.3ms\n",
      "video 1/1 (194/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 car, 1 truck, 16.2ms\n",
      "video 1/1 (195/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.8ms\n",
      "video 1/1 (196/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.9ms\n",
      "video 1/1 (197/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 person, 2 trucks, 17.0ms\n",
      "video 1/1 (198/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.4ms\n",
      "video 1/1 (199/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 3 trucks, 16.6ms\n",
      "video 1/1 (200/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.3ms\n",
      "video 1/1 (201/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.7ms\n",
      "video 1/1 (202/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.5ms\n",
      "video 1/1 (203/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 2 trucks, 17.1ms\n",
      "video 1/1 (204/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 2 trucks, 16.7ms\n",
      "video 1/1 (205/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (206/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.3ms\n",
      "video 1/1 (207/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.0ms\n",
      "video 1/1 (208/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (209/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.4ms\n",
      "video 1/1 (210/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.7ms\n",
      "video 1/1 (211/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.5ms\n",
      "video 1/1 (212/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.3ms\n",
      "video 1/1 (213/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 18.3ms\n",
      "video 1/1 (214/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.7ms\n",
      "video 1/1 (215/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.2ms\n",
      "video 1/1 (216/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.7ms\n",
      "video 1/1 (217/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.5ms\n",
      "video 1/1 (218/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.4ms\n",
      "video 1/1 (219/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 17.0ms\n",
      "video 1/1 (220/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.3ms\n",
      "video 1/1 (221/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 15.9ms\n",
      "video 1/1 (222/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 buss, 1 truck, 16.7ms\n",
      "video 1/1 (223/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.0ms\n",
      "video 1/1 (224/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.2ms\n",
      "video 1/1 (225/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (226/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.1ms\n",
      "video 1/1 (227/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 17.0ms\n",
      "video 1/1 (228/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.6ms\n",
      "video 1/1 (229/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 16.0ms\n",
      "video 1/1 (230/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.5ms\n",
      "video 1/1 (231/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.4ms\n",
      "video 1/1 (232/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 2 trucks, 16.6ms\n",
      "video 1/1 (233/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.1ms\n",
      "video 1/1 (234/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 car, 1 truck, 16.9ms\n",
      "video 1/1 (235/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 truck, 15.8ms\n",
      "video 1/1 (236/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 16.9ms\n",
      "video 1/1 (237/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.1ms\n",
      "video 1/1 (238/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 2 trucks, 16.9ms\n",
      "video 1/1 (239/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 14.4ms\n",
      "video 1/1 (240/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 car, 2 trucks, 15.7ms\n",
      "video 1/1 (241/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 2 trucks, 15.6ms\n",
      "video 1/1 (242/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 car, 2 trucks, 15.2ms\n",
      "video 1/1 (243/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 2 trucks, 15.1ms\n",
      "video 1/1 (244/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 2 trucks, 16.4ms\n",
      "video 1/1 (245/1659) /home/irman/Documents/yolov9/videos/jalan_tol.mp4: 384x640 1 bus, 1 car, 2 trucks, 15.2ms\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/irman/Documents/yolov9/detect_dual.py\", line 232, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/irman/Documents/yolov9/detect_dual.py\", line 227, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/detect_dual.py\", line 98, in run\n",
      "    pred = model(im, augment=augment, visualize=visualize)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/models/common.py\", line 875, in forward\n",
      "    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/models/yolo.py\", line 633, in forward\n",
      "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
      "  File \"/home/irman/Documents/yolov9/models/yolo.py\", line 533, in _forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/models/common.py\", line 613, in forward\n",
      "    y.extend((m(y[-1])) for m in [self.cv2, self.cv3])\n",
      "  File \"/home/irman/Documents/yolov9/models/common.py\", line 613, in <genexpr>\n",
      "    y.extend((m(y[-1])) for m in [self.cv2, self.cv3])\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/models/common.py\", line 384, in forward\n",
      "    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/Documents/yolov9/models/common.py\", line 57, in forward_fuse\n",
      "    return self.act(self.conv(x))\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/irman/anaconda3/envs/yolov9_env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python detect_dual.py --source 'videos/jalan_tol.mp4' --img 640 --device 0 --weights 'runs/train/yolov9-m-finetuning/weights/best.pt' --name yolov9_m_640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
